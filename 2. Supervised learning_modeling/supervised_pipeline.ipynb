{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531db890-5733-42de-991b-4186085c4bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, MultiLabelBinarizer\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from scipy.sparse import hstack, csr_matrix, save_npz, load_npz\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.calibration import calibration_curve\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "def load_and_clean_data(path):\n",
    "    df = pd.read_csv(path, encoding=\"ISO-8859-1\")\n",
    "    df[['runtimeMinutes', 'startYear']] = df[['runtimeMinutes', 'startYear']].replace('\\\\N', np.nan)\n",
    "    df['runtimeMinutes'] = pd.to_numeric(df['runtimeMinutes'], errors='coerce')\n",
    "    df['startYear'] = pd.to_numeric(df['startYear'], errors='coerce')\n",
    "    df['runtimeMinutes'] = df['runtimeMinutes'].fillna(df['runtimeMinutes'].median())\n",
    "    df['startYear'] = df['startYear'].fillna(df['startYear'].median())\n",
    "    return df\n",
    "\n",
    "\n",
    "def generate_labels(df):\n",
    "    df = df[df['avg_rating'].notna()]\n",
    "    df['avg_rating'] = df['avg_rating'].astype(int)\n",
    "    df['label'] = df['avg_rating'].apply(lambda x: 0 if x <= 2 else 1)\n",
    "    return df\n",
    "\n",
    "\n",
    "def load_or_generate_bert_embeddings(df, path=\"bert_mpnet_embeddings.npy\"):\n",
    "    if os.path.exists(path):\n",
    "        print(f\"Loading BERT embeddings from {path}...\")\n",
    "        return np.load(path)\n",
    "    else:\n",
    "        print(\"Generating BERT embeddings...\")\n",
    "        model = SentenceTransformer('all-mpnet-base-v2')\n",
    "        plots = df['plot'].fillna('').tolist()\n",
    "        embeddings = model.encode(plots, show_progress_bar=True).astype(np.float32)\n",
    "        np.save(path, embeddings)\n",
    "        print(f\"Embeddings saved to {path}.\")\n",
    "        return embeddings\n",
    "\n",
    "\n",
    "def multi_hot_encode_with_others(df, column, top_k=None):\n",
    "    df[column + '_list'] = df[column].fillna('').apply(lambda x: [s.strip() for s in x.split(',') if s.strip()])\n",
    "    all_items = df[column + '_list'].explode()\n",
    "    if top_k:\n",
    "        top_items = set(all_items.value_counts().nlargest(top_k).index)\n",
    "        df[column + '_list'] = df[column + '_list'].apply(lambda lst: [x if x in top_items else 'Others' for x in lst])\n",
    "    mlb = MultiLabelBinarizer()\n",
    "    return pd.DataFrame(mlb.fit_transform(df[column + '_list']), columns=[f\"{column}_{c}\" for c in mlb.classes_])\n",
    "\n",
    "\n",
    "def assemble_features(df, X_text):\n",
    "    genres = multi_hot_encode_with_others(df, 'genres')\n",
    "    actors = multi_hot_encode_with_others(df, 'actors', top_k=100)\n",
    "    writers = multi_hot_encode_with_others(df, 'writer', top_k=50)\n",
    "    directors = multi_hot_encode_with_others(df, 'director', top_k=20)\n",
    "    countries = multi_hot_encode_with_others(df, 'country', top_k=20)\n",
    "    languages = multi_hot_encode_with_others(df, 'language', top_k=10)\n",
    "\n",
    "    X_cat_df = pd.concat([genres, actors, writers, directors, countries, languages], axis=1)\n",
    "    X_cat = csr_matrix(X_cat_df.values)\n",
    "\n",
    "    X_num_df = df[['runtimeMinutes', 'startYear', 'num_rating']]\n",
    "    X_num = StandardScaler().fit_transform(X_num_df)\n",
    "    \n",
    "    feature_names = (\n",
    "        [f\"text_{i}\" for i in range(X_text.shape[1])] +\n",
    "        list(X_cat_df.columns) +\n",
    "        list(X_num_df.columns)\n",
    "    )\n",
    "\n",
    "    return hstack([csr_matrix(X_text), X_cat, X_num]), feature_names\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, labels, title=\"Confusion Matrix\"):\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=labels)\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=labels, yticklabels=labels)\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"True\")\n",
    "    plt.title(title)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_feature_importance(model, feature_names, top_n=10):\n",
    "    importances = model.feature_importances_\n",
    "    indices = np.argsort(importances)[-top_n:]\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.barh(range(len(indices)), importances[indices], align=\"center\")\n",
    "    plt.yticks(range(len(indices)), [feature_names[i] for i in indices])\n",
    "    plt.xlabel(\"Importance\")\n",
    "    plt.title(\"Top Feature Importances\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_roc_curve_multi(y_test, probas_dict):\n",
    "    plt.figure(figsize=(7, 6))\n",
    "    for model_name, proba in probas_dict.items():\n",
    "        fpr, tpr, _ = roc_curve(y_test, proba)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        plt.plot(fpr, tpr, lw=2, label=f\"{model_name} (AUC = {roc_auc:.2f})\")\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], linestyle=\"--\", color=\"gray\")\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.title(\"ROC Curve (All Models)\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_model_performance(results):\n",
    "    df_perf = pd.DataFrame([\n",
    "        {\"Model\": name, \"Accuracy\": res['accuracy'], \"F1-score\": res['f1_score']}\n",
    "        for name, res in results.items()\n",
    "    ])\n",
    "    df_perf.set_index(\"Model\")[[\"Accuracy\", \"F1-score\"]].plot(kind=\"bar\", figsize=(8, 5), ylim=(0, 1))\n",
    "    plt.title(\"Model Performance Comparison\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_pr_curve_multi(y_test, probas_dict):\n",
    "    plt.figure(figsize=(7, 6))\n",
    "    for model_name, proba in probas_dict.items():\n",
    "        precision, recall, _ = precision_recall_curve(y_test, proba)\n",
    "        plt.plot(recall, precision, lw=2, label=model_name)\n",
    "\n",
    "    plt.xlabel(\"Recall\")\n",
    "    plt.ylabel(\"Precision\")\n",
    "    plt.title(\"Precision-Recall Curve (All Models)\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_calibration_curve_multi(y_test, probas_dict):\n",
    "    plt.figure(figsize=(7, 6))\n",
    "    for model_name, proba in probas_dict.items():\n",
    "        prob_true, prob_pred = calibration_curve(y_test, proba, n_bins=10)\n",
    "        plt.plot(prob_pred, prob_true, marker='o', label=model_name)\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], linestyle=\"--\", color=\"gray\", label=\"Perfectly Calibrated\")\n",
    "    plt.xlabel(\"Mean Predicted Probability\")\n",
    "    plt.ylabel(\"Fraction of Positives\")\n",
    "    plt.title(\"Calibration Curve (All Models)\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ms2)",
   "language": "python",
   "name": "ms2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
